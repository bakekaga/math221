\documentclass[main.tex]{subfiles}
\begin{document}
\section{Chapter 1}
\subsection{Day 2: 8/24/22}

\subsubsection{Vectors in $\RR^n$}
\begin{definition}
    Suppose $n\in \NN$. Then \vocab{$\RR^n$} is the set of all $(x_1, \ldots , x_n)$ such that $x_1, \ldots , x_n\in \RR$ Formally, $\RR^n = \{(x_1, \ldots , x_n) : x_1, \ldots , x_n\in \RR\}$, where $(x_1, \ldots , x_n)$ are \vocab{$n$-tuples} with components $x_1, \ldots , x_n$.
\end{definition}

\begin{definition}[Vectors]
    \vocab{Vectors} can be thought of as points in $\RR^n$ or as ``arrows" pointing at a point. We define $\vec{0}$ as the $n$-tuple with only 0s (i.e. $(0, \ldots , 0)$). Note that $\vec{0}$s coming from different $\RR^n$s are different objects. We define $\vec{e}_1 = (1, 0, \ldots , 0), \vec{e}_2 = (0, 1, \ldots , 0), \ldots \vec{e}_n = (0, 0, \ldots , 1)$ as the \vocab{standard basis vectors}. Similarly to $\vec{0}$, the standard basis vectors from different $\RR^n$s are different objects even though they are denoted the same.
\end{definition}

We will eventually start denoting vectors in $\RR^n$ by $\begin{pmatrix} x_1 \\ \vdots \\ x_n\end{pmatrix}$ instead of as $n$-tuples when we start working with matrices. Also, some basic properties of vectors:
\begin{itemize}
    \item \vocab{Addition}: if $\vec{x} = (x_1, \ldots , x_n), \vec{y} = (y_1, \ldots , y_n)\in \RR^n$, then we define $\vec{x} + \vec{y} = (x_1 + y_1, \ldots , x_n + y_n)$.
    \item \vocab{Scalar multiplication}: if $\vec{x} = (x_1, \ldots , x_n)\in \RR^n$ and $\lambda\in \RR$, then we define $\lambda\vec{x} = (\lambda x_1, \ldots , \lambda x_n)$.
    \item If we have any vector $\vec{x} = (x_1, \ldots , x_n)\in \RR^n$, then we can express $\vec{x}$ as $\sum_{i = 1}^n x_ie_i = x_1\vec{e}_1 + x_2\vec{e}_2 + \ldots + x_n\vec{e}_n$.
\end{itemize}

\begin{definition}[Norm]
    For $\vec{x} = (x_1, \ldots , x_n)\in \RR^n$, we define the \vocab{length}/\vocab{norm} of the vector $\vec{x}$ as
    \[\norm{\vec{x}} = \sqrt{x_1^2 + \ldots + x_n^2} \ge 0.\]
\end{definition}

Some basic properties of the norm:
\begin{enumerate}
    \item $\norm{\vec{x}} = 0 \iff \vec{x} = \vec{0}$.
    \item $\norm{\lambda\vec{x}} = \abs{\lambda}\norm{\vec{x}}$.
\end{enumerate}

\begin{proof}
    Suppose that $\vec{x} = (x_1, \ldots , x_n)\in \RR^n$.
    \begin{enumerate}
        \item $(\impliedby)$: We're assuming that $\vec{x} = \vec{0} = (0, \ldots , 0)$. Then $\norm{\vec{x}} = \sqrt{0^2 + \ldots + 0^2} = 0$ as desired.

        $(\implies)$: We're assuming that
        \[\norm{\vec{x}} = 0 \implies \norm{\vec{x}}^2 = 0\implies x_1^2 + \ldots + x_n^2 = 0 (\spadesuit).\]
        We know that $x_1^2, \ldots , x_n^2 \ge 0$, so the only way for $(\spadesuit)$ to be true is if all the $x_1, \ldots , x_n$ are equal to $0$, meaning that $\vec{x}$ has to be $\vec{0}$. Alternatively, we can use a proof my contradiction: suppose, for contradiction, that we have $\norm{\vec{x}} = 0$ and $\vec{x}\neq \vec{0}$. Note that for some $i\in \{1, \ldots , n\}$ we have $x_i\neq 0$ (otherwise $\vec{x} = \vec{0}$). Using the fact that $x_i^2 > 0$, it follows that $\norm{\vec{x}}^2 = x_1^2 + \ldots + x_n^2 > 0$, which is a contradiction. Thus $\vec{x} = \vec{0}$ if $\norm{\vec{x}} = 0$.
        \item Observe that
        \begin{align*}
            \norm{\lambda \vec{x}} &= \norm{(\lambda x_1, \ldots , \lambda x_n)} \\
            &= \sqrt{(\lambda x_1)^2 + \ldots + (\lambda x_n)^2} \\
            &= \sqrt{\lambda^2(x_1^2 + \ldots + x_n^2)} \\
            &= \abs{\lambda}\sqrt{x_1^2 + \ldots + x_n^2} \\
            &= \abs{\lambda}\norm{\vec{x}}
        \end{align*}
        as desired.\qedhere
    \end{enumerate}
\end{proof}

\subsubsection{Dot Products and Angles Between Vectors}

\begin{definition}[Dot Product]
    For $\vec{x} = (x_1, \ldots , x_n), \vec{y} = (y_1, \ldots , y_n)\in \RR^n$, we define
    \[\vec{x}\cdot \vec{y} = x_1y_1 + \ldots + x_ny_n\in \RR.\]
\end{definition}

Suppose $\vec{x}, \vec{y}, \vec{z}\in \RR^n$ and $\lambda, \mu\in \RR$. Here's some basic properties:
\begin{enumerate}
    \item $\vec{x}\cdot\vec{y} = \vec{y}\cdot\vec{x}$.
    \item $(\lambda\vec{x} + \mu\vec{y})\cdot \vec{z} = \lambda (\vec{x}\cdot \vec{z}) + \mu (\vec{y}\cdot \vec{z})$.
    \item $\vec{x}\cdot \vec{x} = \norm{\vec{x}}^2$.
\end{enumerate}

We will not prove them as they are fairly straightforward computations. Let's use these basic properties to demonstrate a highly useful lemma:

\begin{lemma}
    Suppose $\vec{x}, \vec{y}\in \RR^n$. Then
    \[\norm{\vec{x} + \vec{y}}^2 = \norm{\vec{x}}^2 + 2\vec{x}\cdot \vec{y} + \norm{\vec{y}}^2.\]
\end{lemma}
\begin{proof}
    Observe that
    \begin{align*}
    \norm{\vec{x} + \vec{y}}^2 &= (\vec{x} + \vec{y})\cdot (\vec{x} + \vec{y}) && \textbf{(basic property 3)}\\
    &= \vec{x} \cdot (\vec{x} + \vec{y}) + \vec{y} \cdot (\vec{x} + \vec{y}) && \textbf{(basic property 2)}\\
    &= (\vec{x} + \vec{y})\cdot \vec{x} + (\vec{x} + \vec{y})\cdot \vec{y} && \textbf{(basic property 1)} \\
    &= \vec{x} \cdot \vec{y} + \vec{y}\cdot \vec{x} + \vec{x} + \vec{y} + \vec{y} \cdot \vec{y} && \textbf{(basic property 2)} \\
    &= \vec{x} \cdot \vec{x} + 2\vec{x}\cdot \vec{y} + \vec{y}\cdot \vec{y} && \textbf{(basic property 1)} \\
    &= \norm{\vec{x}}^2 + 2\vec{x}\cdot \vec{y} + \norm{\vec{y}}^2 && \textbf{(basic property 3)}
    \end{align*}
\end{proof}
\end{document}